# a4ocr
OCR of a scan of a A4 image as markdown using chatgpt
Usage: a4ocr IMAGE


# chatgpt

chatgpt - Submit a prompt to ChatGPT conversation and print the response to stdout. The prompt can be given on the command line or read from stdin.

Usage: chatgpt [options] [prompt]

Input Options:
  -               Reads prompt from stdin; if a prompt is given on the command line it is appended
  -f filename     Includes the content of the given [f]ile as additional message in https://www.stoerr.net/blog/aimouth pattern. 
                  Can be given multiple times. if - is given as filename, the content is read from stdin.
  -fo filename    Same as -f but the [f]ile is [o]ptional.
  -ff filenames   Like -f, but for multiple text [ff]iles - all further arguments are treated as filenames until there is a switch.
  -fp filename    Includes the content of the given [f]ile as codeblock into the [p]rompt, together with the filename. Can be given multiple times.
  -i imagefile    Includes the given image file as [i]mage, together with the filename. Can be given multiple times.
  -iu imageurl    Includes the given [i]mage [u]rl as image, together with the url. Can be given multiple times.
  -id detaillevel Sets the image [d]etail level. Can be 'low', 'high', or 'auto'. Default is 'auto'.
  -a audiofile    Includes the given audio file as [a]udio. Can be given multiple times.
  -au audiourl    Includes the given [a]udio [u]rl as audio. Can be given multiple times.
  -af format      Sets the audio [f]ormat, if not obvious from the file name or url. Can be 'mp3', 'wav'. Default is 'mp3'.
  
Prompt Options:
  -p prefix       Prefix the [p]rompt with a string.
  -pf prefixfile  Prefix the [p]rompt with the contents of a [f]ile
  -pl key         Add a prompt from the ChatGPT [p]rompt [l]ibrary using the given key (see script chatgptpromptlib)
  -pa             Prefix the [p]rompt with recorded [a]udio from the microphone until a key is pressed (transcribed using chatgptdictate)
  -u suffix       S[u]ffix the prompt with a string (that is, append that to the prompt)
  -uf suffixfile  S[u]ffix the prompt with the contents of a [f]ile
  -ua             S[u]ffix the prompt with recorded [a]udio from the microphone until a key is pressed (transcribed using chatgptdictate)

System Message Options:
  -s systemmsg    Use the given string as [s]ystem message
  -sf systemfile  Use as [s]ystem message the contents of the given file
  -sl key         Add a [s]ystem message from the ChatGPT prompt [l]ibrary using the given key with chatgptpromptlib

Conversation Options: (only 1 turn per call chatgpt except with -cr/ca; the conversation state is kept in a file)
  -cf convfile    Use the given file to keep a [c]onversation state [f]ile. Either creates this file or updates it after the answer is received.
  -cn             Starts a new stored [c]onversation: a [n]ew file in directory $HOME/.chatgpt.js/conversations is created and used as conversation state.
  -cc             [C]onversation [c]ontinue for the last conversation: the last file in directory $HOME/.chatgpt.js/conversations is used as conversation state.
  -cl convfile    [C]onversation [l]oad from the given file and uses it for the conversation, but is not updating the file.
  -cd             [C]onversation file [d]elete: removes the last automatically created conversation file (-cn) and then exits.
  -cp             [C]onversation - [p]rints the conversation state as JSON and then exits. Use -cc or -cf to specify which file to print.
  -cr             [C]onversation - multi tu[r]n conversation - abort the program to end this. Each message is finished with Ctrl-D.
  -ca             [C]onversation - multi turn conversation with dictated [a]udio - abort the program to end this.

Request Settings etc.:
  -m modelname    Use a specific [m]odel (default: gpt-4o-mini)
  -mh             Use the [m]odel with - at the time of updating this script - [h]ighest general intelligence ("gpt-4.5-preview")
  -md             Use the [m]odel with - at the time of updating this script - best [d]eliberation ("o3-mini" , -o reasoning_effort=high)
  -t number       Set max [t]okens for response (default: no limit)
  -nr number      Generate this [n]umber of [r]esponses in a row (default: 1). Works only in simple settings - no tools etc.
  -v              [V]erbose output : prints the sent and received json message to stderr and gives info about connection retries
  -w column       [W]ord wrap the response to a specified column width using fmt.
  -abbrev         [Abbrev]iate ("clip") the message in the middle if it's too long for the model context window
  -api url        Use this URL instead of the OpenAI chat completion [API] (e.g. for local LLM or OpenAI compatible APIs)
  -rh key=value   Add a [r]equest [h]eader, e.g. for authorization etc. Can be given multiple times.
  -o key=value    Other [o]ptions, e.g. for the OpenAI API -o temperature=0.5 . Can be given multiple times.
  -of key=file    Other [o]ptions read from a json [f]ile. Can be given multiple times.
  -ocf cfgfile    [O|ption [c]onfiguration [f]ile: read general options from a file.
  -op prof,prof.. [O]ption [p]rofile: like -ocf but reads the options from the named files in ~/.chatgpt.js/profiles/
  --              Last option - option parsing stops, the rest is taken as prompt. E.g. for finishing a -ff list.

Response Options:
  -rj             [R]esponse mode JSON: model outputs a JSON object
  -rf schemafile  Structured output: requests that the [r]esponse conforms to the given JSON schema read from a [f]ile.
  -ra attr1,...   Structured output [r]esponse - JSON with [a]ttributes: comma separated list of attributes to include in the JSON response.
                  Alternative to -rf - creates a simple schema with these attributes. The attributes can have a type
                  as suffix, possibly with [] indicating an array, and with : a description. E.g.:
                  "name[], surname, age int, height number: height in meters, random boolean[]"
  -rar attr1,...  Structured output for JSON [r]esponse [ar]ray of objects with the given attributes - e.g. for extracting
                  a list of entities from an input. Alternative to -rf and -ra, attribute syntax like with -ra.

Tooling options:
  -tf configfile  Use the given file as [t]ools configuration [f]ile for tools the LLM could use. Can be given multiple times.
  -ts toolscript  Use the given script as [t]ool [s]cript for the LLM to use. It has to output a tools configuration file 
                  to stdout when called with parameter --openaitoolsconfig.
  -tt             [T]hink [t]ool - add a pseudo tool the AI can write thoughts to, e.g. for some chain of thought prompting
                  when you want JSON output that doesn't have room for discussion. Outputs the thoughts to stderr.

Help Options:
  -h, --help      Show this [h]elp message
  -ha, --helpai   Answer a question about the tool from this [h]elptext using [A]I and exit. The rest of the command line (prompt) is the question.
  
If the prompt or system message contain a construct like promptlib:key , the chatgptpromptlib command will be called with that key
and this will be replaced with the prompt library entry, as an alternative to -pl key .

The conversation files contain JSON arrays of the conversation messages.

A tools config file contains an array of tool definitions: {"function":{"name":...,"description:"...", "parameters":..., "strict":...},
"commandline: [...], "stdin": ...}. The commandline array is used to call the tool, and stdin is the input for the tool.
In the command line array and stdin, $args is replaced by the arguments given to the tool, and $toolcall is replaced by the tool call JSON. 
In the case of a toolscript: if there is no commandline or stdin given, the script is just called with the tool call JSON.

From https://github.com/stoerr/chatGPTtools .



# chatgptapplytemplate
Apply a ChatGPT chat template to a file and print the result ChatGPT returns to stdout
Usage: /Users/hps/dev/ml/chatgpt/bin/chatgptapplytemplate templateName fileName
       argument 1 is the name of the template file
       argument 2 is the name of the file to apply the template to


# chatgptcreateimage
Illegal option: --
Usage: chatgptimage [options] [prompt]

Generates an image based on a textual prompt using OpenAI's DALL-E 3 model.

If no prompt is given in the command line, -f must be used to specify a file containing the prompt.
If no output file is given, the raw json response is printed to stdout.

Options:
  -h                       Show this help message and exit.
  -m <model>               Model to use for image generation (defaults to dall-e-3).
  -q <quality>             Image quality: standard or hd (Optional, defaults to standard).
  -s <size>                Image size (Optional, overrides -p and -l if used).
  -p                       Use portrait orientation (1024x1792).
  -l                       Use landscape orientation (1792x1024).
  -f <file>                Read prompt from a file. Use '-' to read from stdin.
  -r <format>              Response format url or b64_json (Optional, defaults to url).
  -o <file>                Output file to write the image to (format .png). Implies response_format b64_json.
  -u                       Just prints the url to stdout. (Implies response_format url).
  -v                       View in a file viewer (MacOS open -W); if no -o is given, the file is deleted after viewing (temporary file).

Environment:
  OPENAI_API_KEY           API key for OpenAI. Sourced from this environment variable, or $HOME/.openai-api-key.txt file.

Examples:
  chatgptimage "A panoramic view of Mount Everest"
  chatgptimage -p -m dall-e-3 "A portrait of a young artist as a refined gentleman"
  chatgptimage -l -q hd -f prompts.txt
  echo "A still life of various fruits on a table" | chatgptimage -f -


# chatgptdictate
  Usage: chatgptdictate [-t time] [-o output_file] [-p prompt] [-l language]
  This script records audio from the microphone and sends it to chatgpttranscript and outputs it as text.
  The audio is recorded until a key is pressed, or until the maximum duration is reached.
    -t     maximum duration in seconds, default is 60 seconds
    -o     output file to write the response to. If not provided, the response will be printed to stdout.
    -p     Text to guide the model's style. Optional.
    -l     code of the input audio. Optional but improves accuracy.
    -w     wait with recording until a key is pressed. Default is to start recording immediately.
    -h, --help  Show this help message and exit


# chatgptembedding
Usage: /Users/hps/dev/ml/chatgpt/bin/chatgptembedding [options] <file>
Options:
  -h, --help          Show this help message
  -m, --model <model> Specify the embedding model to use. Default is text-embedding-3-small


# chatgptextractcodeblock
Usage: chatgptExtractCodeblock [options]

Description:
  Extracts and prints the contents of a code block delimited by triple backticks from stdin.
  The code block can be inline or multiline.

Options:
  -n, --invert         Print everything except the code block.
  --help               Show this help message and exit.



# chatgptfixfile
Usage: chatgptfixfile [options] [filepath] [prompt]
A script to modify a file using the ChatGPT API and display the differences.

Options:
  -f <additionalfile>  Add an additional file to be passed to ChatGPT with -f option (can be used multiple times)
  -m <modelname>       Use a specific model (default: gpt-4o-mini)
  --help               Display this help text and exit

Arguments:
  filepath             Path of the file to be modified
  prompt               Prompt to send to ChatGPT

Description:
The script calls ChatGPT with the given file and prompt, extracts a code block from the output, and creates a new file with the changes. It then displays the differences between the original and the new file using 'idea diff'.


# chatgptjq
Extracts from a JSON file read from stdin by applying a jq command generated by ChatGPT from your prompt
Usage e.g.: cat jsonfile | /Users/hps/dev/ml/chatgpt/bin/chatgptjq prompt
Additional options:
  -f jsonfile: read the JSON from the file jsonfile instead of stdin
  -h, --help, -?: print this help message
  -v, --verbose: print the request sent to the LLM
  -s, --silent: do not print the command run with jq
  -n, --no-run: print the command line but do not run it.


# chatgptlistmodels
chatgptlistmodels lists all models available for chatgpt


# chatgptpmcodev
chatgpt with additional tools like the CoDeveloper GPT engine: list files, read files, write files, fetch url
call e.g. with -cr to have a conversation, -m o3-mini if you want an advanced model

chatgpt - Submit a prompt to ChatGPT conversation and print the response to stdout. The prompt can be given on the command line or read from stdin.

Usage: chatgpt [options] [prompt]

Input Options:
  -               Reads prompt from stdin; if a prompt is given on the command line it is appended
  -f filename     Includes the content of the given [f]ile as additional message in https://www.stoerr.net/blog/aimouth pattern. 
                  Can be given multiple times. if - is given as filename, the content is read from stdin.
  -fo filename    Same as -f but the [f]ile is [o]ptional.
  -ff filenames   Like -f, but for multiple text [ff]iles - all further arguments are treated as filenames until there is a switch.
  -fp filename    Includes the content of the given [f]ile as codeblock into the [p]rompt, together with the filename. Can be given multiple times.
  -i imagefile    Includes the given image file as [i]mage, together with the filename. Can be given multiple times.
  -iu imageurl    Includes the given [i]mage [u]rl as image, together with the url. Can be given multiple times.
  -id detaillevel Sets the image [d]etail level. Can be 'low', 'high', or 'auto'. Default is 'auto'.
  -a audiofile    Includes the given audio file as [a]udio. Can be given multiple times.
  -au audiourl    Includes the given [a]udio [u]rl as audio. Can be given multiple times.
  -af format      Sets the audio [f]ormat, if not obvious from the file name or url. Can be 'mp3', 'wav'. Default is 'mp3'.
  
Prompt Options:
  -p prefix       Prefix the [p]rompt with a string.
  -pf prefixfile  Prefix the [p]rompt with the contents of a [f]ile
  -pl key         Add a prompt from the ChatGPT [p]rompt [l]ibrary using the given key (see script chatgptpromptlib)
  -pa             Prefix the [p]rompt with recorded [a]udio from the microphone until a key is pressed (transcribed using chatgptdictate)
  -u suffix       S[u]ffix the prompt with a string (that is, append that to the prompt)
  -uf suffixfile  S[u]ffix the prompt with the contents of a [f]ile
  -ua             S[u]ffix the prompt with recorded [a]udio from the microphone until a key is pressed (transcribed using chatgptdictate)

System Message Options:
  -s systemmsg    Use the given string as [s]ystem message
  -sf systemfile  Use as [s]ystem message the contents of the given file
  -sl key         Add a [s]ystem message from the ChatGPT prompt [l]ibrary using the given key with chatgptpromptlib

Conversation Options: (only 1 turn per call chatgpt except with -cr/ca; the conversation state is kept in a file)
  -cf convfile    Use the given file to keep a [c]onversation state [f]ile. Either creates this file or updates it after the answer is received.
  -cn             Starts a new stored [c]onversation: a [n]ew file in directory $HOME/.chatgpt.js/conversations is created and used as conversation state.
  -cc             [C]onversation [c]ontinue for the last conversation: the last file in directory $HOME/.chatgpt.js/conversations is used as conversation state.
  -cl convfile    [C]onversation [l]oad from the given file and uses it for the conversation, but is not updating the file.
  -cd             [C]onversation file [d]elete: removes the last automatically created conversation file (-cn) and then exits.
  -cp             [C]onversation - [p]rints the conversation state as JSON and then exits. Use -cc or -cf to specify which file to print.
  -cr             [C]onversation - multi tu[r]n conversation - abort the program to end this. Each message is finished with Ctrl-D.
  -ca             [C]onversation - multi turn conversation with dictated [a]udio - abort the program to end this.

Request Settings etc.:
  -m modelname    Use a specific [m]odel (default: gpt-4o-mini)
  -mh             Use the [m]odel with - at the time of updating this script - [h]ighest general intelligence ("gpt-4.5-preview")
  -md             Use the [m]odel with - at the time of updating this script - best [d]eliberation ("o3-mini" , -o reasoning_effort=high)
  -t number       Set max [t]okens for response (default: no limit)
  -nr number      Generate this [n]umber of [r]esponses in a row (default: 1). Works only in simple settings - no tools etc.
  -v              [V]erbose output : prints the sent and received json message to stderr and gives info about connection retries
  -w column       [W]ord wrap the response to a specified column width using fmt.
  -abbrev         [Abbrev]iate ("clip") the message in the middle if it's too long for the model context window
  -api url        Use this URL instead of the OpenAI chat completion [API] (e.g. for local LLM or OpenAI compatible APIs)
  -rh key=value   Add a [r]equest [h]eader, e.g. for authorization etc. Can be given multiple times.
  -o key=value    Other [o]ptions, e.g. for the OpenAI API -o temperature=0.5 . Can be given multiple times.
  -of key=file    Other [o]ptions read from a json [f]ile. Can be given multiple times.
  -ocf cfgfile    [O|ption [c]onfiguration [f]ile: read general options from a file.
  -op prof,prof.. [O]ption [p]rofile: like -ocf but reads the options from the named files in ~/.chatgpt.js/profiles/
  --              Last option - option parsing stops, the rest is taken as prompt. E.g. for finishing a -ff list.

Response Options:
  -rj             [R]esponse mode JSON: model outputs a JSON object
  -rf schemafile  Structured output: requests that the [r]esponse conforms to the given JSON schema read from a [f]ile.
  -ra attr1,...   Structured output [r]esponse - JSON with [a]ttributes: comma separated list of attributes to include in the JSON response.
                  Alternative to -rf - creates a simple schema with these attributes. The attributes can have a type
                  as suffix, possibly with [] indicating an array, and with : a description. E.g.:
                  "name[], surname, age int, height number: height in meters, random boolean[]"
  -rar attr1,...  Structured output for JSON [r]esponse [ar]ray of objects with the given attributes - e.g. for extracting
                  a list of entities from an input. Alternative to -rf and -ra, attribute syntax like with -ra.

Tooling options:
  -tf configfile  Use the given file as [t]ools configuration [f]ile for tools the LLM could use. Can be given multiple times.
  -ts toolscript  Use the given script as [t]ool [s]cript for the LLM to use. It has to output a tools configuration file 
                  to stdout when called with parameter --openaitoolsconfig.
  -tt             [T]hink [t]ool - add a pseudo tool the AI can write thoughts to, e.g. for some chain of thought prompting
                  when you want JSON output that doesn't have room for discussion. Outputs the thoughts to stderr.

Help Options:
  -h, --help      Show this [h]elp message
  -ha, --helpai   Answer a question about the tool from this [h]elptext using [A]I and exit. The rest of the command line (prompt) is the question.
  
If the prompt or system message contain a construct like promptlib:key , the chatgptpromptlib command will be called with that key
and this will be replaced with the prompt library entry, as an alternative to -pl key .

The conversation files contain JSON arrays of the conversation messages.

A tools config file contains an array of tool definitions: {"function":{"name":...,"description:"...", "parameters":..., "strict":...},
"commandline: [...], "stdin": ...}. The commandline array is used to call the tool, and stdin is the input for the tool.
In the command line array and stdin, $args is replaced by the arguments given to the tool, and $toolcall is replaced by the tool call JSON. 
In the case of a toolscript: if there is no commandline or stdin given, the script is just called with the tool call JSON.

From https://github.com/stoerr/chatGPTtools .



# chatgptpromptlib
Usage:
  chatgptpromptlib [-d variable=value] ... promptkey1 promptkey2 ...    output of prompt fragments with key promptkey1 promptkey2 ...
  chatgptpromptlib -l                           lists all promptfragments
  chatgptpromptlib -c category                  lists all promptfragments of category c
  chatgptpromptlib -s searchstring              lists all promptfragments where all words of the searchstring appear

Description:
The prompt fragments are located in the directory $SCRIPTDIR/../promptlib/
and are named like the key but with the extension .prompt.txt.
The first line of the file can specify a category, e.g., CATEGORY=thecategory.
The second line can provide a description, e.g., DESCRIPTION=a description of the file.
These lines are not included in the output.


# chatgptsearchascript
Usage: chatgptsearchascript [options] [task description]

Options:
 -h, --help          Show this help message and exit

Description:
  This script searches for a suitable ChatGPT related command line utility to perform a task
  whose description is given in the command line arguments.


# chatgptspeak
/Users/hps/dev/ml/chatgpt/bin/chatgptspeak: illegal option -- -
Usage: chatgptspeak [-m model] [-v voice] [-r format] [-s speed] [-o output_file] [-f text_file] [input_text]

Generates audio from input text using OpenAI's TTS models.

Arguments:
  input_text           The text input to generate audio for (if -f is not used). Read from stdin if not provided.

Options:
  -m model             Model ID to use for text-to-speech. Default is 'tts-1'.
  -v voice             Voice to use for the generated audio. Default is 'shimmer'. Supported voices are alloy, echo, fable, onyx, nova, and shimmer.
  -r format            Audio format of the response. Default is 'mp3'. Supported are mp3, opus, aac, flac, wav, pcm.
  -s speed             Speed of the generated audio, from 0.25 to 4.0. Default is 1.
  -o output_file       Output file to write the audio to. If not provided, audio will be played using afplay.
  -f text_file         Read input text from a file instead of stdin or command argument.

If no output file is specified with -o, the generated speech will be played immediately using the 'afplay' command.
The script requires an OpenAI API key, which it will attempt to read from the OPENAI_API_KEY environment variable or the file $HOME/.openai-api-key.txt.


# chatgptsummarizefile
Usage: chatgptsummarizefile [options] file

Options:
  --help          Show this help message and exit

Description:
  This script creates a summary of a file. The output format is like this:
---
filename: <filename>
---
# <title>
<1 paragraph summary>


# chatgptsummarizeurl
Usage: chatgptsummarizeurl [options] url

Options:
  -h, --help          Show this help message and exit

Description:
  This script fetches the content of an URL (returning html) and sends a request to summarize the content to ChatGPT.


# chatgpttokentool
CAUTION: the result is not quite correct yet - there is a merging process that is't implemented yet.

Usage: chatgpttokentool [option] inputfile

Options:
  -h or --help  Show this help message and exit
  -c            prints the token count for the input file (NOT QUITE CORRECT - merging not implemented yet)
  -e            prints a quick estimation of the token count for the input file (faster than -c)
  -n            prints the token numbers for the input file separated by one space
  -nv           prints the tokens for the input as token number, tab, token, newline
  -d            the input file must be a whitespace separated token list; decodes that into the original text and prints it
  -sm number    shortens the input file to at most the given number of tokens by cutting off the middle
  -ss number    shortens the input file to at most the given number of tokens by cutting off the start
  -se number    shortens the input file to at most the given number of tokens by cutting off the end

Description:
  There always has to be exactly one option given (possibly including a number) and the input file.
  This script uses tokenization according to ChatGPT-3.5 / ChatGPT-4 tokenization with cl100k_base .
  If the input file is given as - then the input is read from stdin.
  If the input file is shortened, the removed part is replaced by ' ... ' . If there is no need for shortening, the input is printed as is.



# chatgpttranscription
Invalid option --
Usage: chatgpttranscription [-m model] [-l language] [-p prompt] [-r response_format] [-o output_file] <audio_file>
  -m  Model ID to use for transcription. Default is 'whisper-1'.
  -l  Language code of the input audio. Optional but improves accuracy.
  -p  Text to guide the model's style. Optional.
  -r  Response format of the transcript output. Options: text, vtt, json, srt, verbose_json. Default is 'text'.
  -o  Output file to write the response to. If not provided, the response will be printed to stdout.
  -t  Trim the output - remove any whitespace at beginning and end of the response.
  -h  Show this help message and exit.
  <audio_file> The audio file to transcribe.


# claude

claude - Submit a prompt to Claude conversation and print the response to stdout. The prompt can be given on the command line or read from stdin.

Usage: claude [options] [prompt]

Options:
  -               Reads prompt from stdin; if a prompt is given on the command line it is appended
  -f filename     Includes the content of the given file as additional message in https://www.stoerr.net/blog/aimouth pattern. 
                  Can be given multiple times. if - is given as filename, the content is read from stdin.
  -fp filename    Includes the content of the given file as codeblock into the prompt, together with the filename. Can be given multiple times.
  -i imagefile    Includes the given image file as image, together with the filename. Can be given multiple times.
  -iu imageurl    Includes the given image url as image, together with the url. Can be given multiple times.
  -p prefix       Prefix the prompt with a string. Use this or -pf, not both.
  -pf prefixfile  Prefix the prompt with the contents of a file
  -pl key         Add a prompt from the ChatGPT prompt library using the given key (see script chatgptpromptlib)
  -pa             Record audio from the microphone until a key is pressed (using chatgptdictate) and use the result as prompt prefis
  -u suffix       Suffix the prompt with a string. Use this or -sf, not both.
  -uf suffixfile  Suffix the prompt with the contents of a file
  -ua             Record audio from the microphone until a key is pressed (using chatgptdictate) and use the result as prompt suffix
  -m modelname    Use a specific model (default: claude-3-haiku-20240307)
  -mh             Use the model with - the time of updating this script - highest intelligence (claude-3-5-sonnet-20240620). 
  -t number       Set max tokens for response (default: 4096)
  -v              verbose output : prints the sent and received json message to stderr and gives info about connection retries
  -w column       Word wrap the response to a specified column width using fmt.
  -s systemmsg    Use the given string as system message
  -sf systemfile  Use the contents of the given file as system message
  -sl key         Add a system message from the ChatGPT prompt library using the given key with chatgptpromptlib
  -h, --help      Show this help message
  -ha, --helpai   Answer a question about the tool from this helptext and exit. The rest of the command line (prompt) is the question.
  
If the prompt or system message contain a construct like promptlib:key , the chatgptpromptlib command will be called with that key
and this will be replaced with the prompt library entry, as an alternative to -pl key .



# createJavaUnittest
Usage: createJavaUnittest [options] [Java file] [optional additional instructions]

Options:
  -f              Overwrite existing test file if it exists
  -y systemmsg    Use the given string as system message (compare -y for chatgpt script)
  -h, --help      Show this help message and exit

Description:
  This script generates a JUnit 4 test for the given Java file using ChatGPT.
  The output test file is placed in the corresponding 'src/test/java'
  directory with a 'Test.java' suffix.


# findfilewithpattern

findfilewithpattern - searches for files with IntelliJ style pattern.

Usage: findfilewithpattern [pattern]

Options:
    -h, --help          Show this help message and exit

Examples:
    findfilewithpattern src/main/**/MyFile*java
    
Details:
    - * are wildcards within a file / directory name
    - ** are wildcards that can span directories (that is, matches foo/bar/baz)
    - the matching is case insensitive
    - on boundaries between uppercase and lowercase there are implicit * wildcards - e.g. fooBaz will match FoOBARbaz



# findprogram
Usage: findprogram {program description}
Searches in the PATH for programs that do what the description says.


# q
Usage: q [chatgpt arguments] [prompt]

This script asks chatgpt for something with a quick answer.
Additional arguments can be given for chatgpt, e.g. -fm file, -4, -
Full usage of chatgpt for more arguments:

chatgpt - Submit a prompt to ChatGPT conversation and print the response to stdout. The prompt can be given on the command line or read from stdin.

Usage: chatgpt [options] [prompt]

Input Options:
  -               Reads prompt from stdin; if a prompt is given on the command line it is appended
  -f filename     Includes the content of the given [f]ile as additional message in https://www.stoerr.net/blog/aimouth pattern. 
                  Can be given multiple times. if - is given as filename, the content is read from stdin.
  -fo filename    Same as -f but the [f]ile is [o]ptional.
  -ff filenames   Like -f, but for multiple text [ff]iles - all further arguments are treated as filenames until there is a switch.
  -fp filename    Includes the content of the given [f]ile as codeblock into the [p]rompt, together with the filename. Can be given multiple times.
  -i imagefile    Includes the given image file as [i]mage, together with the filename. Can be given multiple times.
  -iu imageurl    Includes the given [i]mage [u]rl as image, together with the url. Can be given multiple times.
  -id detaillevel Sets the image [d]etail level. Can be 'low', 'high', or 'auto'. Default is 'auto'.
  -a audiofile    Includes the given audio file as [a]udio. Can be given multiple times.
  -au audiourl    Includes the given [a]udio [u]rl as audio. Can be given multiple times.
  -af format      Sets the audio [f]ormat, if not obvious from the file name or url. Can be 'mp3', 'wav'. Default is 'mp3'.
  
Prompt Options:
  -p prefix       Prefix the [p]rompt with a string.
  -pf prefixfile  Prefix the [p]rompt with the contents of a [f]ile
  -pl key         Add a prompt from the ChatGPT [p]rompt [l]ibrary using the given key (see script chatgptpromptlib)
  -pa             Prefix the [p]rompt with recorded [a]udio from the microphone until a key is pressed (transcribed using chatgptdictate)
  -u suffix       S[u]ffix the prompt with a string (that is, append that to the prompt)
  -uf suffixfile  S[u]ffix the prompt with the contents of a [f]ile
  -ua             S[u]ffix the prompt with recorded [a]udio from the microphone until a key is pressed (transcribed using chatgptdictate)

System Message Options:
  -s systemmsg    Use the given string as [s]ystem message
  -sf systemfile  Use as [s]ystem message the contents of the given file
  -sl key         Add a [s]ystem message from the ChatGPT prompt [l]ibrary using the given key with chatgptpromptlib

Conversation Options: (only 1 turn per call chatgpt except with -cr/ca; the conversation state is kept in a file)
  -cf convfile    Use the given file to keep a [c]onversation state [f]ile. Either creates this file or updates it after the answer is received.
  -cn             Starts a new stored [c]onversation: a [n]ew file in directory $HOME/.chatgpt.js/conversations is created and used as conversation state.
  -cc             [C]onversation [c]ontinue for the last conversation: the last file in directory $HOME/.chatgpt.js/conversations is used as conversation state.
  -cl convfile    [C]onversation [l]oad from the given file and uses it for the conversation, but is not updating the file.
  -cd             [C]onversation file [d]elete: removes the last automatically created conversation file (-cn) and then exits.
  -cp             [C]onversation - [p]rints the conversation state as JSON and then exits. Use -cc or -cf to specify which file to print.
  -cr             [C]onversation - multi tu[r]n conversation - abort the program to end this. Each message is finished with Ctrl-D.
  -ca             [C]onversation - multi turn conversation with dictated [a]udio - abort the program to end this.

Request Settings etc.:
  -m modelname    Use a specific [m]odel (default: gpt-4o-mini)
  -mh             Use the [m]odel with - at the time of updating this script - [h]ighest general intelligence ("gpt-4.5-preview")
  -md             Use the [m]odel with - at the time of updating this script - best [d]eliberation ("o3-mini" , -o reasoning_effort=high)
  -t number       Set max [t]okens for response (default: no limit)
  -nr number      Generate this [n]umber of [r]esponses in a row (default: 1). Works only in simple settings - no tools etc.
  -v              [V]erbose output : prints the sent and received json message to stderr and gives info about connection retries
  -w column       [W]ord wrap the response to a specified column width using fmt.
  -abbrev         [Abbrev]iate ("clip") the message in the middle if it's too long for the model context window
  -api url        Use this URL instead of the OpenAI chat completion [API] (e.g. for local LLM or OpenAI compatible APIs)
  -rh key=value   Add a [r]equest [h]eader, e.g. for authorization etc. Can be given multiple times.
  -o key=value    Other [o]ptions, e.g. for the OpenAI API -o temperature=0.5 . Can be given multiple times.
  -of key=file    Other [o]ptions read from a json [f]ile. Can be given multiple times.
  -ocf cfgfile    [O|ption [c]onfiguration [f]ile: read general options from a file.
  -op prof,prof.. [O]ption [p]rofile: like -ocf but reads the options from the named files in ~/.chatgpt.js/profiles/
  --              Last option - option parsing stops, the rest is taken as prompt. E.g. for finishing a -ff list.

Response Options:
  -rj             [R]esponse mode JSON: model outputs a JSON object
  -rf schemafile  Structured output: requests that the [r]esponse conforms to the given JSON schema read from a [f]ile.
  -ra attr1,...   Structured output [r]esponse - JSON with [a]ttributes: comma separated list of attributes to include in the JSON response.
                  Alternative to -rf - creates a simple schema with these attributes. The attributes can have a type
                  as suffix, possibly with [] indicating an array, and with : a description. E.g.:
                  "name[], surname, age int, height number: height in meters, random boolean[]"
  -rar attr1,...  Structured output for JSON [r]esponse [ar]ray of objects with the given attributes - e.g. for extracting
                  a list of entities from an input. Alternative to -rf and -ra, attribute syntax like with -ra.

Tooling options:
  -tf configfile  Use the given file as [t]ools configuration [f]ile for tools the LLM could use. Can be given multiple times.
  -ts toolscript  Use the given script as [t]ool [s]cript for the LLM to use. It has to output a tools configuration file 
                  to stdout when called with parameter --openaitoolsconfig.
  -tt             [T]hink [t]ool - add a pseudo tool the AI can write thoughts to, e.g. for some chain of thought prompting
                  when you want JSON output that doesn't have room for discussion. Outputs the thoughts to stderr.

Help Options:
  -h, --help      Show this [h]elp message
  -ha, --helpai   Answer a question about the tool from this [h]elptext using [A]I and exit. The rest of the command line (prompt) is the question.
  
If the prompt or system message contain a construct like promptlib:key , the chatgptpromptlib command will be called with that key
and this will be replaced with the prompt library entry, as an alternative to -pl key .

The conversation files contain JSON arrays of the conversation messages.

A tools config file contains an array of tool definitions: {"function":{"name":...,"description:"...", "parameters":..., "strict":...},
"commandline: [...], "stdin": ...}. The commandline array is used to call the tool, and stdin is the input for the tool.
In the command line array and stdin, $args is replaced by the arguments given to the tool, and $toolcall is replaced by the tool call JSON. 
In the case of a toolscript: if there is no commandline or stdin given, the script is just called with the tool call JSON.

From https://github.com/stoerr/chatGPTtools .



# qa
Usage: qa [chatgpt arguments] [prompt]

This script asks chatgpt for something with a quick answer, using audio input to dictate the prompt.
Terminate the dictation with any key press.
Additional arguments can be given for chatgpt, e.g. -fm file, -4, -
Full usage of chatgpt for more arguments:

chatgpt - Submit a prompt to ChatGPT conversation and print the response to stdout. The prompt can be given on the command line or read from stdin.

Usage: chatgpt [options] [prompt]

Input Options:
  -               Reads prompt from stdin; if a prompt is given on the command line it is appended
  -f filename     Includes the content of the given [f]ile as additional message in https://www.stoerr.net/blog/aimouth pattern. 
                  Can be given multiple times. if - is given as filename, the content is read from stdin.
  -fo filename    Same as -f but the [f]ile is [o]ptional.
  -ff filenames   Like -f, but for multiple text [ff]iles - all further arguments are treated as filenames until there is a switch.
  -fp filename    Includes the content of the given [f]ile as codeblock into the [p]rompt, together with the filename. Can be given multiple times.
  -i imagefile    Includes the given image file as [i]mage, together with the filename. Can be given multiple times.
  -iu imageurl    Includes the given [i]mage [u]rl as image, together with the url. Can be given multiple times.
  -id detaillevel Sets the image [d]etail level. Can be 'low', 'high', or 'auto'. Default is 'auto'.
  -a audiofile    Includes the given audio file as [a]udio. Can be given multiple times.
  -au audiourl    Includes the given [a]udio [u]rl as audio. Can be given multiple times.
  -af format      Sets the audio [f]ormat, if not obvious from the file name or url. Can be 'mp3', 'wav'. Default is 'mp3'.
  
Prompt Options:
  -p prefix       Prefix the [p]rompt with a string.
  -pf prefixfile  Prefix the [p]rompt with the contents of a [f]ile
  -pl key         Add a prompt from the ChatGPT [p]rompt [l]ibrary using the given key (see script chatgptpromptlib)
  -pa             Prefix the [p]rompt with recorded [a]udio from the microphone until a key is pressed (transcribed using chatgptdictate)
  -u suffix       S[u]ffix the prompt with a string (that is, append that to the prompt)
  -uf suffixfile  S[u]ffix the prompt with the contents of a [f]ile
  -ua             S[u]ffix the prompt with recorded [a]udio from the microphone until a key is pressed (transcribed using chatgptdictate)

System Message Options:
  -s systemmsg    Use the given string as [s]ystem message
  -sf systemfile  Use as [s]ystem message the contents of the given file
  -sl key         Add a [s]ystem message from the ChatGPT prompt [l]ibrary using the given key with chatgptpromptlib

Conversation Options: (only 1 turn per call chatgpt except with -cr/ca; the conversation state is kept in a file)
  -cf convfile    Use the given file to keep a [c]onversation state [f]ile. Either creates this file or updates it after the answer is received.
  -cn             Starts a new stored [c]onversation: a [n]ew file in directory $HOME/.chatgpt.js/conversations is created and used as conversation state.
  -cc             [C]onversation [c]ontinue for the last conversation: the last file in directory $HOME/.chatgpt.js/conversations is used as conversation state.
  -cl convfile    [C]onversation [l]oad from the given file and uses it for the conversation, but is not updating the file.
  -cd             [C]onversation file [d]elete: removes the last automatically created conversation file (-cn) and then exits.
  -cp             [C]onversation - [p]rints the conversation state as JSON and then exits. Use -cc or -cf to specify which file to print.
  -cr             [C]onversation - multi tu[r]n conversation - abort the program to end this. Each message is finished with Ctrl-D.
  -ca             [C]onversation - multi turn conversation with dictated [a]udio - abort the program to end this.

Request Settings etc.:
  -m modelname    Use a specific [m]odel (default: gpt-4o-mini)
  -mh             Use the [m]odel with - at the time of updating this script - [h]ighest general intelligence ("gpt-4.5-preview")
  -md             Use the [m]odel with - at the time of updating this script - best [d]eliberation ("o3-mini" , -o reasoning_effort=high)
  -t number       Set max [t]okens for response (default: no limit)
  -nr number      Generate this [n]umber of [r]esponses in a row (default: 1). Works only in simple settings - no tools etc.
  -v              [V]erbose output : prints the sent and received json message to stderr and gives info about connection retries
  -w column       [W]ord wrap the response to a specified column width using fmt.
  -abbrev         [Abbrev]iate ("clip") the message in the middle if it's too long for the model context window
  -api url        Use this URL instead of the OpenAI chat completion [API] (e.g. for local LLM or OpenAI compatible APIs)
  -rh key=value   Add a [r]equest [h]eader, e.g. for authorization etc. Can be given multiple times.
  -o key=value    Other [o]ptions, e.g. for the OpenAI API -o temperature=0.5 . Can be given multiple times.
  -of key=file    Other [o]ptions read from a json [f]ile. Can be given multiple times.
  -ocf cfgfile    [O|ption [c]onfiguration [f]ile: read general options from a file.
  -op prof,prof.. [O]ption [p]rofile: like -ocf but reads the options from the named files in ~/.chatgpt.js/profiles/
  --              Last option - option parsing stops, the rest is taken as prompt. E.g. for finishing a -ff list.

Response Options:
  -rj             [R]esponse mode JSON: model outputs a JSON object
  -rf schemafile  Structured output: requests that the [r]esponse conforms to the given JSON schema read from a [f]ile.
  -ra attr1,...   Structured output [r]esponse - JSON with [a]ttributes: comma separated list of attributes to include in the JSON response.
                  Alternative to -rf - creates a simple schema with these attributes. The attributes can have a type
                  as suffix, possibly with [] indicating an array, and with : a description. E.g.:
                  "name[], surname, age int, height number: height in meters, random boolean[]"
  -rar attr1,...  Structured output for JSON [r]esponse [ar]ray of objects with the given attributes - e.g. for extracting
                  a list of entities from an input. Alternative to -rf and -ra, attribute syntax like with -ra.

Tooling options:
  -tf configfile  Use the given file as [t]ools configuration [f]ile for tools the LLM could use. Can be given multiple times.
  -ts toolscript  Use the given script as [t]ool [s]cript for the LLM to use. It has to output a tools configuration file 
                  to stdout when called with parameter --openaitoolsconfig.
  -tt             [T]hink [t]ool - add a pseudo tool the AI can write thoughts to, e.g. for some chain of thought prompting
                  when you want JSON output that doesn't have room for discussion. Outputs the thoughts to stderr.

Help Options:
  -h, --help      Show this [h]elp message
  -ha, --helpai   Answer a question about the tool from this [h]elptext using [A]I and exit. The rest of the command line (prompt) is the question.
  
If the prompt or system message contain a construct like promptlib:key , the chatgptpromptlib command will be called with that key
and this will be replaced with the prompt library entry, as an alternative to -pl key .

The conversation files contain JSON arrays of the conversation messages.

A tools config file contains an array of tool definitions: {"function":{"name":...,"description:"...", "parameters":..., "strict":...},
"commandline: [...], "stdin": ...}. The commandline array is used to call the tool, and stdin is the input for the tool.
In the command line array and stdin, $args is replaced by the arguments given to the tool, and $toolcall is replaced by the tool call JSON. 
In the case of a toolscript: if there is no commandline or stdin given, the script is just called with the tool call JSON.

From https://github.com/stoerr/chatGPTtools .



# suggestbash
Usage: suggestbash [options] [task description]

Options:
  --help          Show this help message and exit

Description:
  This script sends a task description to ChatGPT, which returns a bash
  command line for the given task and prints it.


# suggestfish
Usage: suggestfish [options] [task description]

Options:
  -h, --help          Show this help message and exit

Description:
  This script sends a task description to ChatGPT, which returns a fish
  command line for the given task and prints it.


# toolsconfigFromCodevActions
Usage: toolsconfigFromCodevActions <tools>
  Prints a configuration file useable with chatgpt -tf for the tools given on the command line.

Options:
  --help          Show this help message and exit

Description:
  This prints a configuration file useable with chatgpt -tf for the tools given on the command line.
  It assumes that these follow the conventions for actions for the
  Co-Developer GPT Engine https://codevelopergptengine.stoerr.net/
  that is, it contains a comment with "Plugin Action:" and a description of the action.


# urltotext
Usage: urltotext url

Options:
  -h, --help          Show this help message and exit

Description:
  This script fetches the content of an URL (returning html) and outputs it as text, incl. some metadata.


