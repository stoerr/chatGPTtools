#!/usr/bin/env node
/**
 * Swiss knive type tool for submitting conversations to ChatGPT and printing the response.
 * Many options and several ways of submitting files or images are supported.
 *
 * @see "https://platform.openai.com/docs/api-reference/chat/create"
 */

const fs = require('fs');
const path = require('path');
const {execSync, spawnSync} = require('child_process');
const readline = require('readline');

let model = 'gpt-4o-mini';
const programname = path.basename(process.argv[1]);
const homeDir = process.env.HOME;

const helpMessage = `
${programname} - Submit a prompt to ChatGPT conversation and print the response to stdout. The prompt can be given on the command line or read from stdin.

Usage: ${programname} [options] [prompt]

Input Options:
  -               Reads prompt from stdin; if a prompt is given on the command line it is appended
  -f filename     Includes the content of the given [f]ile as additional message in https://www.stoerr.net/blog/aimouth pattern. 
                  Can be given multiple times. if - is given as filename, the content is read from stdin.
  -ff filenames   Like -f, but for multiple [ff]iles - all further arguments are treated as filenames until there is a switch.
  -fp filename    Includes the content of the given [f]ile as codeblock into the [p]rompt, together with the filename. Can be given multiple times.
  -i imagefile    Includes the given image file as [i]mage, together with the filename. Can be given multiple times.
  -iu imageurl    Includes the given [i]mage [u]rl as image, together with the url. Can be given multiple times.
  -id detaillevel Sets the image [d]etail level. Can be 'low', 'high', or 'auto'. Default is 'auto'.
  -a audiofile    Includes the given audio file as [a]udio. Can be given multiple times.
  -au audiourl    Includes the given [a]udio [u]rl as audio. Can be given multiple times.
  -af format      Sets the audio [f]ormat, if not obvious from the file name or url. Can be 'mp3', 'wav'. Default is 'mp3'.
  
Prompt Options:
  -p prefix       Prefix the [p]rompt with a string.
  -pf prefixfile  Prefix the [p]rompt with the contents of a [f]ile
  -pl key         Add a prompt from the ChatGPT [p]rompt [l]ibrary using the given key (see script chatgptpromptlib)
  -pa             Prefix the [p]rompt with recorded [a]udio from the microphone until a key is pressed (transcribed using chatgptdictate)
  -u suffix       S[u]ffix the prompt with a string (that is, append that to the prompt)
  -uf suffixfile  S[u]ffix the prompt with the contents of a [f]ile
  -ua             S[u]ffix the prompt with recorded [a]udio from the microphone until a key is pressed (transcribed using chatgptdictate)

System Message Options:
  -s systemmsg    Use the given string as [s]ystem message
  -sf systemfile  Use as [s]ystem message the contents of the given file
  -sl key         Add a [s]ystem message from the ChatGPT prompt [l]ibrary using the given key with chatgptpromptlib

Conversation Options: (only 1 turn per call ${programname} except with -cr/ca; the conversation state is kept in a file)${programname})
  -cf convfile    Use the given file to keep a [c]onversation state [f]ile. Either creates this file or updates it after the answer is received.
  -cn             Starts a new stored [c]onversation: a [n]ew file in directory $HOME/.chatgpt/conversations is created and used as conversation state.
  -cc             [C]onversation [c]ontinue for the last conversation: the last file in directory $HOME/.chatgpt/conversations is used as conversation state.
  -cl convfile    [C]onversation [l]oad from the given file and uses it for the conversation, but is not updating the file.
  -cd             [C]onversation file [d]elete: removes the last automatically created conversation file (-cn) and then exits.
  -cp             [C]onversation - [p]rints the conversation state as JSON and then exits. Use -cc or -cf to specify which file to print.
  -cr             [C]onversation - multi tu[r]n conversation - abort the program to end this. Each message is finished with Ctrl-D.
  -ca             [C]onversation - multi turn conversation with dictated [a]udio - abort the program to end this.

Request Settings etc.:
  -m modelname    Use a specific [m]odel (default: ${model})
  -mh             Use the [m]odel with - the time of updating this script - [h]ighest general intelligence ("gpt-4o")
  -t number       Set max [t]okens for response (default: no limit)
  -v              [V]erbose output : prints the sent and received json message to stderr and gives info about connection retries
  -w column       [W]ord wrap the response to a specified column width using fmt.
  -abbrev         [Abbrev]iate ("clip") the message in the middle if it's too long for the model context window
  -api url        Use this URL instead of the OpenAI chat completion [API] (e.g. for local LLM or OpenAI compatible APIs)
  -o key=value    Other [o]ptions, e.g. for the OpenAI API -o temperature=0.5 . Can be given multiple times.
  -of key=file    Other [o]ptions read from a json [f]ile, e.g. for the OpenAI API tools. Can be given multiple times.
  --              Last option - option parsing stops, the rest is taken as prompt. E.g. for finishing a -ff list.

Response Options:
  -rj             [R]esponse mode JSON: model outputs a JSON object
  -rf schemafile  Structured output: requests that the [r]esponse conforms to the given JSON schema read from a [f]ile.
  -ra attr1,...   Structured output [r]esponse - JSON with [a]ttributes: comma separated list of attributes to include in the JSON response. 
                  Alternative to -rf - creates a simple schema with these attributes as string properties.
  -rar attr1,...  Structured output for JSON [r]esponse [ar]ray of objects with the given attributes - e.g. for extracting
                  a list of entities from an input. Alternative to -rf and -ra , all are string properties.             

Tooling options:
  -tf configfile  Use the given file as [t]ools configuration [f]ile for tools the LLM could use.

Help Options:
  -h, --help      Show this [h]elp message
  -ha, --helpai   Answer a question about the tool from this [h]elptext using [A]I and exit. The rest of the command line (prompt) is the question.
  
If the prompt or system message contain a construct like promptlib:key , the chatgptpromptlib command will be called with that key
and this will be replaced with the prompt library entry, as an alternative to -pl key .

The conversation files contain JSON arrays of the conversation messages.

A tools config file contains an array of tool definitions: {"function":{"name":...,"description:"...", "parameters":..., "strict":...},
"commandline: [...], "stdin": ...}. The commandline array is used to call the tool, and stdin is the input for the tool.
In the command line array and stdin, $args is replaced by the arguments given to the tool, and $toolcall is replaced by the tool call JSON.

From https://github.com/stoerr/chatGPTtools .
`;

if (process.argv.length < 3) {
    console.log(helpMessage);
    process.exit(0);
}

const apiKeyFile = `${process.env.HOME}/.openai-api-key.txt`;
const openAIurldefault = 'https://api.openai.com/v1/chat/completions';
let apiURL = openAIurldefault;
let maxTokens;
let prompt = '';
let inOptions = true;
let readStdin = false;
let verbose = false;
let prefix = '';
let suffix = '';
let files = [];
let fmfiles = [];
let fmfilemessages = [];
let wordWrapColumn;
let systemMsg = '';
let imageFiles = [];
let imageUrls = [];
let detailparam = 'auto';
let abbreviateMiddle = false;
let helpaimode = false;
let dictatedPrefix = false;
let dictatedSuffix = false;
let conversationFile = undefined;
let conversationLoad = undefined;
let conversationPrint = false;
let openAIOptions = {};
let jsonMode = false;
let responseSchemaFile = undefined;
let responseAttributes = undefined;
let responseArrayAttributes = undefined;
let toolsConfigFile = undefined;
let tools = undefined;
let conversationLoopWithReadline = false;
let conversationLoopWithDictate = false;
let audioFiles = [];
let audioUrls = [];
let audioFormat = undefined;

function getConversationDir() {
    const conversationDir = `${process.env.HOME}/.chatgpt/conversations`;
    if (!fs.existsSync(conversationDir)) {
        // we don't want to be intrusive - rather let the user do that
        console.error(`Error: Conversation directory ${conversationDir} does not exist - please create it.`);
        process.exit(1);
    }
    return conversationDir;
}

function getLastConversationFile() {
    const conversationDir = getConversationDir();
    const conversationFiles = fs.readdirSync(conversationDir);
    conversationFiles.sort();
    if (conversationFiles.length === 0) {
        console.error(`Error: No conversation files found in ${conversationDir}.`);
        process.exit(1);
    }
    const lastConversationFile = `${conversationDir}/${conversationFiles[conversationFiles.length - 1]}`;
    return lastConversationFile;
}

for (let i = 2; i < process.argv.length; i++) {
    const arg = process.argv[i];

    if (inOptions) {
        if (arg === '--help' || arg === '-h' || arg === ' -?') {
            console.log(helpMessage);
            process.exit(0);
        } else if (arg === '-m' && process.argv[i + 1]) {
            model = process.argv[i + 1];
            i++;
        } else if (arg === '-4' || arg === "-mh") { // -4 for backwards compatibility
            model = 'gpt-4o';
        } else if (arg === '-t' && process.argv[i + 1]) {
            maxTokens = parseInt(process.argv[i + 1], 10);
            i++;
        } else if (arg === '-') {
            readStdin = true;
        } else if (arg === '-v') {
            verbose = true;
        } else if (arg === '-p' && process.argv[i + 1]) {
            prefix = (prefix ? prefix + '\n\n' : '') + process.argv[i + 1];
            i++;
        } else if (arg === '-pf' && process.argv[i + 1]) {
            prefix = (prefix ? prefix + '\n\n' : '') + fs.readFileSync(process.argv[i + 1], 'utf8');
            i++;
        } else if (arg === '-pl' && process.argv[i + 1]) {
            const promptlibkey = process.argv[i + 1];
            try {
                const promptlibOutput = execSync(`chatgptpromptlib ${promptlibkey}`, {encoding: 'utf8'});
                prompt += '\n' + promptlibOutput + '\n';
            } catch (e) {
                console.error('Error: Prompt library key not found (1): ' + promptlibkey);
                process.exit(1);
            }
            i++;
        } else if (arg === '-u' && process.argv[i + 1]) {
            suffix = (suffix ? suffix + '\n\n' : '') + process.argv[i + 1];
            i++;
        } else if (arg === '-uf' && process.argv[i + 1]) {
            suffix = (suffix ? suffix + '\n\n' : '') + fs.readFileSync(process.argv[i + 1], 'utf8');
            i++;
        } else if (arg === '-s' && process.argv[i + 1]) {
            systemMsg = process.argv[i + 1];
            i++;
        } else if (arg === '-sf' && process.argv[i + 1]) {
            systemMsg = fs.readFileSync(process.argv[i + 1], 'utf8');
            i++;
        } else if (arg === '-sl' && process.argv[i + 1]) {
            const promptlibkey = process.argv[i + 1];
            try {
                systemMsg = execSync(`chatgptpromptlib ${promptlibkey}`, {encoding: 'utf8'});
            } catch (e) {
                console.error('Error: Prompt library key not found (2): ' + promptlibkey);
                process.exit(1);
            }
            i++;
        } else if (arg === '-fp' && process.argv[i + 1]) {
            files.push(process.argv[i + 1]);
            i++;
        } else if ((arg === '-fm' || arg === '-f') && process.argv[i + 1]) { // -fm is for backwards compatibility
            fmfiles.push(process.argv[i + 1]);
            i++;
        } else if (arg === '-ff') {
            while (process.argv[i + 1] && !process.argv[i + 1].startsWith('-')) {
                fmfiles.push(process.argv[i + 1]);
                i++;
            }
        } else if (arg === '-w' && process.argv[i + 1]) {
            wordWrapColumn = parseInt(process.argv[i + 1], 10);
            i++;
        } else if (arg === '-y' && process.argv[i + 1]) {
            systemMsg = process.argv[i + 1];
            i++;
        } else if (arg === '-i' && process.argv[i + 1]) {
            imageFiles.push(process.argv[i + 1]);
            i++;
        } else if (arg === '-iu' && process.argv[i + 1]) {
            imageUrls.push(process.argv[i + 1]);
            i++;
        } else if (arg === '-id' && process.argv[i + 1]) {
            detailparam = process.argv[i + 1];
            i++;
        } else if (arg === '-a' && process.argv[i + 1]) {
            audioFiles.push(process.argv[i + 1]);
            i++;
        } else if (arg === '-au' && process.argv[i + 1]) {
            audioUrls.push(process.argv[i + 1]);
            i++;
        } else if (arg === '-af' && process.argv[i + 1]) {
            audioFormat = process.argv[i + 1];
            i++;
        } else if (arg === '-abbrev') {
            abbreviateMiddle = true;
        } else if (arg === '-pa') {
            dictatedPrefix = true;
        } else if (arg === '-ua') {
            dictatedSuffix = true;
        } else if (arg === '-cf' && process.argv[i + 1]) {
            conversationFile = process.argv[i + 1];
            i++;
        } else if (arg === '-cn') {
            const conversationDir = getConversationDir();
            conversationFile = `${conversationDir}/${new Date().toISOString().replace(/:/g, '-')}.json`;
            console.error(`Creating new conversation file: ${conversationFile}`);
        } else if (arg === '-cc') {
            conversationFile = getLastConversationFile();
            console.error(`Continuing conversation from ${conversationFile}`);
        } else if (arg === '-cl' && process.argv[i + 1]) {
            conversationLoad = process.argv[i + 1];
            i++;
        } else if (arg === '-cd') {
            const lastConversationFile = getLastConversationFile();
            fs.unlinkSync(lastConversationFile);
            console.error(`Conversation file ${lastConversationFile} removed. Exiting.`);
            process.exit(0);
        } else if (arg === '-cp') {
            conversationPrint = true;
        } else if (arg === '-cr') {
            conversationLoopWithReadline = true;
        } else if (arg === '-ca') {
            conversationLoopWithDictate = true;
        } else if (arg === '-o' && process.argv[i + 1]) {
            var [key, value] = process.argv[i + 1].split('=');
            try {
                value = JSON.parse(value);
            } catch (e) {
                // if value is parseable as JSON, parse it, otherwise just take it as string
            }
            openAIOptions[key] = value;
            i++;
        } else if (arg === '-of' && process.argv[i + 1]) {
            var [key, filename] = process.argv[i + 1].split('=');
            try {
                openAIOptions[key] = JSON.parse(fs.readFileSync(resolveFile(filename), 'utf8'));
            } catch (e) {
                console.error('Error: Could not read JSON file: ' + filename);
                process.exit(1);
            }
        } else if (arg === '-rj') {
            jsonMode = true;
        } else if (arg === '-rf' && process.argv[i + 1]) {
            responseSchemaFile = process.argv[i + 1];
            jsonMode = true;
            i++;
        } else if (arg === '-ra' && process.argv[i + 1]) {
            responseAttributes = process.argv[i + 1].split(',');
            jsonMode = true;
            i++;
        } else if (arg === '-rar' && process.argv[i + 1]) {
            responseArrayAttributes = process.argv[i + 1].split(',');
            jsonMode = true;
            i++;
        } else if (arg === '-tf' && process.argv[i + 1]) {
            toolsConfigFile = process.argv[i + 1];
            i++;
        } else if (arg === '-api' && process.argv[i + 1]) {
            apiURL = process.argv[i + 1];
            i++;
        } else if (arg === '-ha' || arg === '--helpai') {
            helpaimode = true;
        } else if (arg === '--') {
            inOptions = false;
        } else if (!arg.startsWith('-')) {
            inOptions = false;
            prompt += arg;
        } else {
            console.error('Error: Unknown option: ' + arg);
            console.error(helpMessage);
            process.exit(1);
        }
    } else {
        prompt += ' ' + arg;
    }
}

const headers = {
    'Content-Type': 'application/json'
};

let messages = [];

function addMessagesFrom(file) {
    // if the file exists, read the conversation from it
    if (fs.existsSync(resolveFile(file))) {
        const conversationJson = fs.readFileSync(resolveFile(file), 'utf-8');
        const newMessages = JSON.parse(conversationJson);
        messages = messages.concat(newMessages);
    } else if (!fs.existsSync(path.dirname(resolveFile(file)))) {
        console.error('Error: Directory for conversation file does not exist: ' + path.dirname(resolveFile(file)));
        process.exit(2);
    }
}

if (conversationFile) {
    addMessagesFrom(conversationFile);
}

if (conversationLoad) {
    addMessagesFrom(conversationLoad);
}

if (conversationPrint) {
    console.log(JSON.stringify(messages, null, 4));
    process.exit(0);
}

if (apiURL === openAIurldefault) { // don't give out the authorization header for other API!
    let apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey && fs.existsSync(apiKeyFile)) {
        apiKey = fs.readFileSync(apiKeyFile, 'utf8').trim();
    }
    headers['Authorization'] = `Bearer ${apiKey}`;
}

if (readStdin) {
    const stdinPrompt = fs.readFileSync(0, 'utf-8');
    prompt = stdinPrompt.trim() + '\n\n' + prompt;
}

prompt = replacePromptlibKey(prompt);

if (prefix) {
    prompt = prefix.trim() + '\n\n' + prompt;
}

if (suffix) {
    prompt = prompt + '\n\n' + suffix.trim();
}

let filecontents = "";

function resolveFile(file) {
    let filename = file;
    return filename.replace('~', homeDir);
}

for (let i = 0; i < fmfiles.length; i++) {
    const file = fmfiles[i];
    if (file === '-') {
        const filecontent = fs.readFileSync(0, 'utf-8');
        fmfilemessages.push({role: 'user', content: "Print the raw input text the instructions will apply to."});
        fmfilemessages.push({role: 'assistant', content: filecontent});
    } else {
        const filecontent = fs.readFileSync(resolveFile(file), 'utf-8');
        fmfilemessages.push({
            role: 'user',
            content: "Print the current raw content of the file " + file.replace(homeDir, '~')
        });
        fmfilemessages.push({role: 'assistant', content: filecontent});
    }
}

for (let i = 0; i < files.length; i++) {
    const file = files[i];
    let filename = file.replace('~', homeDir);
    const filePrompt = fs.readFileSync(resolveFile(file), 'utf-8');

    if (files.length > 1) {
        filecontents = filecontents + "=== FILE " + (i + 1) + ": " + filename + " ===\n```\n" + filePrompt.trim() + "\n```\n";
    } else {
        filecontents = filecontents + "```\n" + filePrompt.trim() + "\n```\n";
    }
}

if (filecontents) {
    prompt = prompt + "\n\n" + filecontents;
}

if (helpaimode) {
    fmfilemessages.push({
        role: 'user',
        content: "Print the help text for the 'chatgpt' tool. You will use that as background knowledge to answer my question."
    });
    fmfilemessages.push({role: 'assistant', content: helpMessage});
}

function dictatePrompt(waitKey = false) {
    if (waitKey) console.log();
    const args = waitKey ? ' -w' : '';
    return execSync('chatgptdictate' + args, {encoding: 'utf8', stdio: ['inherit', 'pipe', 'pipe']});
}

if (dictatedPrefix) {
    const audioPrefix = dictatePrompt();
    if (audioPrefix) {
        console.log('Dicated prompt: ' + audioPrefix.trim());
        prompt = audioPrefix.trim() + '\n\n' + prompt;
    }
}

if (dictatedSuffix) {
    const audioSuffix = dictatePrompt();
    if (audioSuffix) {
        console.log('Dictated prompt suffix: ' + audioSuffix.trim());
        prompt = prompt + '\n\n' + audioSuffix.trim();
    }
}

if ((!prompt || !prompt.trim()) && !conversationLoopWithReadline && !conversationLoopWithDictate) {
    console.error('Error: No prompt provided');
    console.error(helpMessage);
    process.exit(1);
}

if (verbose) {
    console.error('Arguments: ', process.argv);
    console.error('Prompt: ', prompt, '\n');
    console.error('Prompt word count: ', prompt.split(/\s+/).length, '\n');
    console.error("---------------------------------------------\n\n");
}

function addFirstMessage(firstPrompt) {
    let content = firstPrompt;
    // if there is an image or audio input, turn content into an array
    if (imageFiles.length > 0 || imageUrls.length > 0 || audioFiles.length > 0 || audioUrls.length > 0) {
        content = [
            {
                "type": "text",
                "text": firstPrompt
            }
        ];
    }

    if (imageFiles.length > 0 || imageUrls.length > 0) {
        for (let i = 0; i < imageFiles.length; i++) {
            const imageFile = imageFiles[i];

            let imageFileContent;
            if (detailparam === 'low') {
                imageFileContent = execSync(`magick '${imageFile}' -resize '512x512>' jpg:- | base64`, {encoding: 'utf8'});
            } else { // let OpenAI handle the resizing to avoid losing details, but make sure we don't submit huge images
                imageFileContent = execSync(`magick '${imageFile}' -resize '2000x2000>' jpg:- | base64`, {
                    encoding: 'utf8',
                    maxBuffer: 1024 * 1024 * 25
                });
            }
            const imageBase64 = `data:image/jpeg;base64,${imageFileContent.trim()}`;
            content.push({
                "type": "image_url",
                "image_url": {
                    "url": imageBase64,
                    "detail": detailparam
                }
            });
        }
        for (let i = 0; i < imageUrls.length; i++) {
            const imageUrl = imageUrls[i];
            content.push({
                "type": "image_url",
                "image_url": {
                    "url": imageUrl
                }
            });
        }
    }

    if (audioFiles.length > 0 || audioUrls.length > 0) {
        for (let i = 0; i < audioFiles.length; i++) {
            const audioFile = audioFiles[i];
            const audioFileContent = fs.readFileSync(resolveFile(audioFile), 'base64');
            content.push({
                "type": "input_audio",
                "input_audio": {
                    "data": audioFileContent,
                    "format": audioFormat || path.extname(audioFile).slice(1) || 'mp3'
                }
            });
        }
        for (let i = 0; i < audioUrls.length; i++) {
            const audioUrl = audioUrls[i];
            content.push({
                "type": "audio",
                "audio": {
                    "url": audioUrl,
                    "format": audioFormat || path.extname(audioUrl).slice(1)
                }
            });
        }
    }

    messages.push({role: 'user', content: content});
}

const requestData = {
    model: model,
    user: 'chatgpt script'
};

for (const key in openAIOptions) {
    requestData[key] = openAIOptions[key];
}

if (fmfilemessages.length > 0) {
    messages = fmfilemessages.concat(messages);
}

if (systemMsg) {
    messages.unshift({role: 'system', content: replacePromptlibKey(systemMsg)});
}

if (maxTokens) {
    requestData.max_tokens = maxTokens;
}

if (jsonMode) {
    requestData.response_format = {"type": "json_object"};
}

// if it's two of responseSchemaFile, responseAttributes, responseArrayAttributes, we have a conflict
if ((responseSchemaFile && responseAttributes) || (responseSchemaFile && responseArrayAttributes) ||
    (responseAttributes && responseArrayAttributes)) {
    console.error('Error: Cannot use more than one of -rf, -ra and -rar');
    process.exit(1);
}

let schema = undefined;

if (responseSchemaFile) { // see https://platform.openai.com/docs/guides/structured-outputs/introduction
    schema = JSON.parse(fs.readFileSync(resolveFile(responseSchemaFile), 'utf8'));
    // OpenAI schema description https://platform.openai.com/docs/api-reference/chat/create
    if (!schema.name) { // if there is a name we assume this is already an OpenAI description
        schema = {name: "responseschema", schema: schema, strict: true};
    }
}

if (responseAttributes) {
    // create a JSON schema for a simple object that includes exactly those attributes as properties
    schema = {
        "type": "object",
        "properties": {},
        "required": responseAttributes,
        "additionalProperties": false
    };
    for (const attribute of responseAttributes) {
        schema.properties[attribute] = {"type": "string"};
    }
    schema = {name: "responseschema", schema: schema, strict: true};
}

if (responseArrayAttributes) {
    // similar to responseAttributes, but for a list; we wrap that into {data:[...]} since OpenAI doesn't support plain arrays yet
    // for attributes foo,bar the response would be e.g. {data:[{foo:"hi", bar:"ho"},{foo:"hu", bar:"heu"}]}
    schema = {
      "type": "object",
      "properties": {
        "data": {
          "type": "array",
          "items": {
            "type": "object",
            "properties": {},
            "required": [],
            "additionalProperties": false
          }
        }
      },
      "required": ["data"],
      "additionalProperties": false
    }
    for (const attribute of responseArrayAttributes) {
        schema.properties.data.items.properties[attribute] = {"type": "string"};
        schema.properties.data.items.required.push(attribute);
    }
    schema = {name: "responseschema", schema: schema, strict: true};
}

if (schema) {
    requestData.response_format = {
        "type": "json_schema",
        "json_schema": schema
    };
}

if (toolsConfigFile) {
    tools = JSON.parse(fs.readFileSync(resolveFile(toolsConfigFile), 'utf8'));
    requestData.tools = tools.map(tool => ({"type": "function", "function": tool.function}));
}

/** When we receive a message from chatgpt that the request is too long and if the user requested that,
 *  we will replace the middle of the message with " [...] " to make it shorter - we assume that usually the start and the end contain the most information. Since we don't want to bother with tokens here, we will estimate the needed length by the number of characters. */
// example too long errorMsg: This model's maximum context length is 16385 tokens. However, your messages resulted in 31506 tokens. Please reduce the length of the messages.
function abbreviateMessage(errorMsg) {
    let start;
    let end;
    if (errorMsg) {
        const tooLongMatch = errorMsg.match(/maximum context length is (\d+) tokens.*messages resulted in (\d+) tokens/);
        if (!tooLongMatch) { // message format changed - bug, need to fix that
            console.error('Error: Unexpected error message format: ' + errorMsg);
            process.exit(6);
        }
        const modelMaxTokens = parseInt(tooLongMatch[1], 10);
        const messageTokens = parseInt(tooLongMatch[2], 10);
        const messageLength = content.length;
        const wantedLength = (0.9 * modelMaxTokens / messageTokens) * messageLength - 5; // safety margin
        start = content.slice(0, wantedLength / 2);
        end = content.slice(-wantedLength / 2);
    } else { // no message given; we take out a random value of 30%
        start = content.slice(0, 0.35 * content.length);
        end = content.slice(-0.35 * content.length);
    }
    var oldcontent = content;
    content = start + " [...] " + end;
    if (verbose) console.error("Abbreviated message from " + oldcontent.length + " to " + content.length + " characters.");
    // find the message having oldcontent as content and change to the new content - might not be the first message
    for (let i = 0; i < messages.length; i++) {
        if (messages[i].content === oldcontent) {
            messages[i].content = content;
            break;
        }
    }
}

/** Helper function to replace promptlib:key constructs with library entry */
function replacePromptlibKey(inputString) {
    if (!inputString) return inputString;
    const promptlibRegex = /promptlib:([a-zA-Z0-9_.-]+)/g;
    return inputString.replace(promptlibRegex, function (match, key) {
        try {
            return execSync(`chatgptpromptlib ${key}`, {encoding: 'utf8'});
        } catch (e) {
            console.error('Warning: Prompt library key not found (3): ' + key);
        }
    });
}

function writeConversation() {
    if (conversationFile) {
        fs.writeFileSync(resolveFile(conversationFile), JSON.stringify(messages, null, 4));
        if (verbose) {
            console.error('Conversation written to ' + conversationFile);
        }
    }
}

// see https://docs.anthropic.com/en/api/messages
async function requestChatGPT(successcallback, attempt = 1) {
    try {
        requestData.messages = messages;
        if (verbose) console.error("Request: ", JSON.stringify(requestData, null, 4));
        const response = await fetch(apiURL, {
            method: 'POST',
            headers,
            body: JSON.stringify(requestData),
        });
        if (verbose) console.error("Response status: ", response.status);

        if (response.status === 429) {
            const retryMessage = await response.text();
            if (verbose) console.error("Retry message: ", retryMessage);
            var waitTime;
            try {
                waitTime = parseInt(retryMessage.match(/(\d+)s/)[1], 10);
            } catch (e) {
            }
            if (!waitTime || waitTime < 1 || waitTime > 60) {
                console.error('Error: Rate limit exceeded, but no valid retry-after found', retryMessage);
                process.exit(3);
            }

            if (attempt < 5) {
                if (verbose) {
                    console.error(`Error: Rate limit exceeded, retrying in ${waitTime} seconds`);
                }
                setTimeout(() => requestChatGPT(successcallback, attempt + 1), waitTime * 1000);
            } else {
                console.error('Error: Too many retries');
                process.exit(4);
            }
        } else if (response.status === 400) {
            var body = await response.text();
            if (abbreviateMiddle && body.includes("reduce the length of the messages")
                && body.includes("context_length_exceeded")) {
                abbreviateMessage(body);
                setTimeout(() => requestChatGPT(successcallback, attempt + 1), 10);
            } else {
                console.error('Error: Request failed with status', response.status, 'and message', response.statusText, 'and body', body);
                process.exit(5);
            }
        } else if (!response.ok) {
            console.error('Error: Request failed with status', response.status, 'and message', response.statusText, 'and body', await response.text());
            process.exit(5);
        } else {
            const responseData = await response.json();
            if (verbose) console.error("Response: ", JSON.stringify(responseData, null, 4));
            const assistantMessage = responseData.choices[0].message;
            const finishReason = responseData.choices[0].finish_reason;

            if (finishReason === 'length' && abbreviateMiddle) {
                abbreviateMessage();
                setTimeout(() => requestChatGPT(successcallback, attempt + 1), 10);
            } else if (finishReason === 'stop' || finishReason === 'tool_calls' || !finishReason) {
                const msg = {role: 'assistant'};
                if (assistantMessage.content) {
                    msg.content = assistantMessage.content;
                } else if (assistantMessage.tool_calls) {
                    msg.tool_calls = assistantMessage.tool_calls;
                }
                messages.push(msg);
                if (finishReason === 'stop') {
                    writeConversation();
                }

                successcallback(assistantMessage);
            } else {
                console.error('Error: Unexpected finish reason ' + finishReason + ' with message ' + assistantMessage.content);
                process.exit(1);
            }
        }
    } catch (error) {
        console.error('Error:', error.message);
        process.exit(6);
    }
}

function onContent(assistantMessage) {
    let output = assistantMessage.content;
    if (!output) {
        console.error('Error: Unexpected message format: ', assistantMessage);
        process.exit(7);
    }
    writeConversation();
    if (responseArrayAttributes) { // parse as JSON, unwrap {data:[]} to the actual array and print that
        output = JSON.stringify(JSON.parse(output).data);
    }
    if (wordWrapColumn) {
        const fmt = spawnSync('fmt', ['-w', wordWrapColumn, '-p'], {input: output, encoding: 'utf8'});
        if (fmt.error) {
            console.error(`Error: fmt command failed with error ${fmt.error.message}`);
            process.exit(7);
        }
        output = fmt.stdout;
    }
    console.log(output);
    maybeContinueConversation();
}

function onMessage(assistantMessage) {
    const toolCalls = assistantMessage["tool_calls"];
    if (!toolCalls) {
        return onContent(assistantMessage);
    }
    for (const toolCall of toolCalls) {
        const tool = tools.find(tool => tool.function.name === toolCall.function.name);
        let commandline = Array.isArray(tool.commandline) ? tool.commandline.slice() : tool.commandline.split(' ');
        // replace placeholders ($arg) with corresponding tool_call.function.arguments
        const parsedArguments = JSON.parse(toolCall.function.arguments);
        parsedArguments['toolcall'] = JSON.stringify(toolCall.function, null, 2);
        // replace arguments in all parts of the commandline
        for (let i = 0; i < commandline.length; i++) {
            for (const [key, value] of Object.entries(parsedArguments)) {
                commandline[i] = commandline[i].replace('$' + key, value);
            }
        }
        let stdin = tool.stdin;
        if (stdin) {
            for (const [key, value] of Object.entries(parsedArguments)) {
                stdin = stdin.replace('$' + key, value);
            }
        }
        commandline[0] = resolveScript(commandline[0]);
        console.error("Calling tool", toolCall.function.name, ': ', commandline.join(' '),
            'with stdin', stdin.length > 300 ? stdin.slice(0, 300) + '...' : stdin);
        const result = spawnSync(commandline[0], commandline.slice(1), {
            input: stdin,
            encoding: 'utf8',
            timeout: 10000
        });
        if (result.error) {
            console.error('Error: Tool call failed with error', result.error);
            process.exit(8);
        }
        const toolOutput = result.error ? result.error.toString() : result.stderr.toString() + result.stdout.toString();
        messages.push({role: 'tool', content: toolOutput, tool_call_id: toolCall.id});
    }
    writeConversation();
    requestChatGPT(onMessage);
}

function resolveScript(script) {
    if (script.startsWith('/')) {
        return script;
    }
    if (fs.existsSync(script)) {
        return path.resolve(script);
    }
    const relativeToCmdFile = path.join(path.dirname(toolsConfigFile), script);
    if (fs.existsSync(relativeToCmdFile)) {
        return path.resolve(relativeToCmdFile);
    }
    return script;
}

function readMessageAndContine(continuecallback) {
    const rl = readline.createInterface({
        input: process.stdin,
        output: process.stdout,
        prompt: '\nType your next message, end with Ctrl-D or "/end" on a line on itself; end with an empty message.\n',
    });

    let inputBuffer = '';
    rl.on('line', (line) => {
        if (line.trim() === '/end') {
            rl.close();
        } else {
            inputBuffer += line + '\n';
        }
    }).on('SIGINT', () => {
        process.exit(130);
    }).on('close', () => {
        console.log('(processing)');
        continuecallback(inputBuffer);
    });
    rl.prompt();
}

function maybeContinueConversation() {
    if (conversationLoopWithReadline) {
        readMessageAndContine((inputBuffer) => {
            if (inputBuffer.trim() === '') {
                process.exit(0);
            }
            messages.push({role: 'user', content: inputBuffer});
            requestChatGPT(onMessage);
        });
    } else if (conversationLoopWithDictate) {
        const dictatedMessage = dictatePrompt(true);
        if (dictatedMessage) {
            console.log('Dicated message: ' + dictatedMessage.trim());
            messages.push({role: 'user', content: dictatedMessage});
            console.log();
            requestChatGPT(onMessage);
        }
    }
}

const mainCallback = toolsConfigFile ? onMessage : onContent;

if (prompt) {
    addFirstMessage(prompt);
    requestChatGPT(mainCallback);
} else if (conversationLoopWithReadline) {
    readMessageAndContine(
        (prompt) => {
            addFirstMessage(prompt);
            requestChatGPT(mainCallback);
        }
    );
} else if (conversationLoopWithDictate) {
    const dictatedMessage = dictatePrompt(false);
    console.log('Dicated message: ' + dictatedMessage.trim());
    console.log();
    addFirstMessage(dictatedMessage);
    requestChatGPT(mainCallback);
} else {
    console.error('Bug? No prompt given and not in conversation loop mode.');
}
