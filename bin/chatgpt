#!/usr/bin/env node
/**
 * Swiss knive type tool for submitting conversations to ChatGPT and printing the response.
 * Many options and several ways of submitting files or images are supported.
 *
 * @see "https://platform.openai.com/docs/api-reference/chat/create"
 */

const fs = require('fs');
const path = require('path');
const { execSync, spawnSync } = require('child_process');

let model = 'gpt-4o-mini';
const programname = path.basename(process.argv[1]);
const homeDir = process.env.HOME;

const helpMessage = `
${programname} - Submit a prompt to ChatGPT conversation and print the response to stdout. The prompt can be given on the command line or read from stdin.

Usage: ${programname} [options] [prompt]

Input Options:
  -               Reads prompt from stdin; if a prompt is given on the command line it is appended
  -f filename     Includes the content of the given file as additional message in https://www.stoerr.net/blog/aimouth pattern. 
                  Can be given multiple times. if - is given as filename, the content is read from stdin.
  -fp filename    Includes the content of the given file as codeblock into the prompt, together with the filename. Can be given multiple times.
  -i imagefile    Includes the given image file as image, together with the filename. Can be given multiple times.
  -iu imageurl    Includes the given image url as image, together with the url. Can be given multiple times.
  -id detaillevel Sets the detail level for the image. Can be 'low', 'high', or 'auto'. Default is 'auto'.
  
Prompt Options:
  -p prefix       Prefix the prompt with a string. Use this or -pf, not both.
  -pf prefixfile  Prefix the prompt with the contents of a file
  -pl key         Add a prompt from the ChatGPT prompt library using the given key (see script chatgptpromptlib)
  -pa             Record audio from the microphone until a key is pressed (using chatgptdictate) and use the result as prompt prefis
  -u suffix       Suffix the prompt with a string. Use this or -sf, not both.
  -uf suffixfile  Suffix the prompt with the contents of a file
  -ua             Record audio from the microphone until a key is pressed (using chatgptdictate) and use the result as prompt suffix

System Message Options:
  -s systemmsg    Use the given string as system message
  -sf systemfile  Use the contents of the given file as system message
  -sl key         Add a system message from the ChatGPT prompt library using the given key with chatgptpromptlib

Conversation Options:
  -cf convfile    Use the given file to keep a conversation state. Either creates this file or updates it after the answer is received.
  -cn             Starts a new conversation: a new file in directory $HOME/.chatgpt/conversations is created and used as conversation state.
  -cc             Continues the last conversation: the last file in directory $HOME/.chatgpt/conversations is used as conversation state.
  -cl convfile    Loads the conversation state from the given file and uses it for the conversation, but is not updating the file.
  -cr             Removes the last created conversation file and then exits.
  -cp             Prints the conversation state as JSON and then exits. Use -cc or -cf to specify which file to print.

Request Settings etc.:
  -m modelname    Use a specific model (default: ${model})
  -mh             Use the model with - the time of updating this script - highest intelligence ("gpt-4o")
  -t number       Set max tokens for response (default: no limit)
  -v              verbose output : prints the sent and received json message to stderr and gives info about connection retries
  -w column       Word wrap the response to a specified column width using fmt.
  -a              Abbreviate ("clip") the message in the middle if it's too long for the model context window
  -api url        Use this URL instead of the OpenAI chat completion API (e.g. for local LLM or OpenAI compatible APIs)
  -o key=value    Other options, e.g. for the OpenAI API -o temperature=0.5 . Can be given multiple times.
  -of key=file    Other options read from a json file, e.g. for the OpenAI API tools. Can be given multiple times.

Response Options:
  -rj             JSON mode: model outputs a JSON object
  -rf schemafile  Structured output: requests that the response conforms to the given JSON schema read from a file.

Tooling options:
  -tf configfile  Use the given file as tools configuration file for tools the LLM could use.

Help Options:
  -h, --help      Show this help message
  -ha, --helpai   Answer a question about the tool from this helptext and exit. The rest of the command line (prompt) is the question.
  
If the prompt or system message contain a construct like promptlib:key , the chatgptpromptlib command will be called with that key
and this will be replaced with the prompt library entry, as an alternative to -pl key .

The conversation files contain JSON arrays of the conversation messages.

A tools config file contains an array of tool definitions: {"function":{"name":...,"description:"...", "parameters":..., "strict":...},
"commandline: [...], "stdin": ...}. The commandline array is used to call the tool, and stdin is the input for the tool.
`;

if (process.argv.length < 3) {
    console.log(helpMessage);
    process.exit(0);
}

const apiKeyFile = `${process.env.HOME}/.openai-api-key.txt`;
const openAIurldefault = 'https://api.openai.com/v1/chat/completions';
let apiURL = openAIurldefault;
let maxTokens;
let prompt = '';
let inOptions = true;
let readStdin = false;
let verbose = false;
let prefix = '';
let suffix = '';
let files = [];
let fmfiles = [];
let fmfilemessages = [];
let wordWrapColumn;
let systemMsg = '';
let imageFiles = [];
let imageUrls = [];
let detailparam = 'auto';
let abbreviateMiddle = false;
let helpaimode = false;
let audioPrefix = false;
let audioSuffix = false;
let conversationFile = undefined;
let conversationLoad = undefined;
let conversationPrint = false;
let openAIOptions = {};
let jsonMode = false;
let responseSchemaFile = undefined;
let toolsConfigFile = undefined;
let tools = undefined;

function getConversationDir() {
    const conversationDir = `${process.env.HOME}/.chatgpt/conversations`;
    if (!fs.existsSync(conversationDir)) {
        // we don't want to be intrusive - rather let the user do that
        console.error(`Error: Conversation directory ${conversationDir} does not exist - please create it.`);
        process.exit(1);
    }
    return conversationDir;
}

function getLastConversationFile() {
    const conversationDir = getConversationDir();
    const conversationFiles = fs.readdirSync(conversationDir);
    conversationFiles.sort();
    if (conversationFiles.length === 0) {
        console.error(`Error: No conversation files found in ${conversationDir}.`);
        process.exit(1);
    }
    const lastConversationFile = `${conversationDir}/${conversationFiles[conversationFiles.length - 1]}`;
    return lastConversationFile;
}

for (let i = 2; i < process.argv.length; i++) {
    const arg = process.argv[i];

    if (inOptions) {
        if (arg === '--help' || arg === '-h' || arg === ' -?') {
            console.log(helpMessage);
            process.exit(0);
        } else if (arg === '-m' && process.argv[i + 1]) {
            model = process.argv[i + 1];
            i++;
        } else if (arg === '-4' || arg === "-mh") { // -4 for backwards compatibility
            model = 'gpt-4o';
        } else if (arg === '-t' && process.argv[i + 1]) {
            maxTokens = parseInt(process.argv[i + 1], 10);
            i++;
        } else if (arg === '-') {
            readStdin = true;
        } else if (arg === '-v') {
            verbose = true;
        } else if (arg === '-p' && process.argv[i + 1]) {
            prefix = process.argv[i + 1];
            i++;
        } else if (arg === '-pf' && process.argv[i + 1]) {
            prefix = fs.readFileSync(process.argv[i + 1], 'utf8');
            i++;
        } else if (arg === '-pl' && process.argv[i + 1]) {
            const promptlibkey = process.argv[i + 1];
            try {
                const promptlibOutput = execSync(`chatgptpromptlib ${promptlibkey}`, {encoding: 'utf8'});
                prompt += '\n' + promptlibOutput + '\n';
            } catch (e) {
                console.error('Error: Prompt library key not found (1): ' + promptlibkey);
                process.exit(1);
            }
            i++;
        } else if (arg === '-u' && process.argv[i + 1]) {
            suffix = process.argv[i + 1];
            i++;
        } else if (arg === '-uf' && process.argv[i + 1]) {
            suffix = fs.readFileSync(process.argv[i + 1], 'utf8');
            i++;
        } else if (arg === '-s' && process.argv[i + 1]) {
            systemMsg = process.argv[i + 1];
            i++;
        } else if (arg === '-sf' && process.argv[i + 1]) {
            systemMsg = fs.readFileSync(process.argv[i + 1], 'utf8');
            i++;
        } else if (arg === '-sl' && process.argv[i + 1]) {
            const promptlibkey = process.argv[i + 1];
            try {
                systemMsg = execSync(`chatgptpromptlib ${promptlibkey}`, {encoding: 'utf8'});
            } catch (e) {
                console.error('Error: Prompt library key not found (2): ' + promptlibkey);
                process.exit(1);
            }
            i++;
        } else if (arg === '-fp' && process.argv[i + 1]) {
            files.push(process.argv[i + 1]);
            i++;
        } else if ((arg === '-fm' || arg === '-f') && process.argv[i + 1]) { // -fm is for backwards compatibility
            fmfiles.push(process.argv[i + 1]);
            i++;
        } else if (arg === '-w' && process.argv[i + 1]) {
            wordWrapColumn = parseInt(process.argv[i + 1], 10);
            i++;
        } else if (arg === '-y' && process.argv[i + 1]) {
            systemMsg = process.argv[i + 1];
            i++;
        } else if (arg === '-i' && process.argv[i + 1]) {
            imageFiles.push(process.argv[i + 1]);
            i++;
        } else if (arg === '-iu' && process.argv[i + 1]) {
            imageUrls.push(process.argv[i + 1]);
            i++;
        } else if (arg === '-id' && process.argv[i + 1]) {
            detailparam = process.argv[i + 1];
            i++;
        } else if (arg === '-a') {
            abbreviateMiddle = true;
        } else if (arg === '-pa') {
            audioPrefix = true;
        } else if (arg === '-ua') {
            audioSuffix = true;
        } else if (arg === '-cf' && process.argv[i + 1]) {
            conversationFile = process.argv[i + 1];
            i++;
        } else if (arg === '-cn') {
            const conversationDir = getConversationDir();
            conversationFile = `${conversationDir}/${new Date().toISOString().replace(/:/g, '-')}.json`;
        } else if (arg === '-cc') {
            conversationFile = getLastConversationFile();
        } else if (arg === '-cl' && process.argv[i + 1]) {
            conversationLoad = process.argv[i + 1];
            i++;
        } else if (arg === '-cr') {
            const lastConversationFile = getLastConversationFile();
            fs.unlinkSync(lastConversationFile);
            console.error(`Conversation file ${lastConversationFile} removed. Exiting.`);
            process.exit(0);
        } else if (arg === '-cp') {
            conversationPrint = true;
        } else if (arg === '-o' && process.argv[i + 1]) {
            var [key, value] = process.argv[i + 1].split('=');
            try {
                value = JSON.parse(value);
            } catch (e) {
                // if value is parseable as JSON, parse it, otherwise just take it as string
            }
            openAIOptions[key] = value;
            i++;
        } else if (arg === '-of' && process.argv[i + 1]) {
            var [key, filename] = process.argv[i + 1].split('=');
            try {
                openAIOptions[key] = JSON.parse(fs.readFileSync(resolveFile(filename), 'utf8'));
            } catch (e) {
                console.error('Error: Could not read JSON file: ' + filename);
                process.exit(1);
            }
        } else if (arg === '-rj') {
            jsonMode = true;
        } else if (arg === '-rf' && process.argv[i + 1]) {
            responseSchemaFile = process.argv[i + 1];
            i++;
        } else if (arg === '-tf' && process.argv[i + 1]) {
            toolsConfigFile = process.argv[i + 1];
            i++;
        } else if (arg === '-api' && process.argv[i + 1]) {
            apiURL = process.argv[i + 1];
            i++;
        } else if (arg === '-ha' || arg === '--helpai') {
            helpaimode = true;
        } else if (!arg.startsWith('-')) {
            inOptions = false;
            prompt += arg;
        } else {
            console.error('Error: Unknown option: ' + arg);
            console.error(helpMessage);
            process.exit(1);
        }
    } else {
        prompt += ' ' + arg;
    }
}

const headers = {
    'Content-Type': 'application/json'
};

let messages = [];

function addMessagesFrom(file) {
    // if the file exists, read the conversation from it
    if (fs.existsSync(resolveFile(file))) {
        const conversationJson = fs.readFileSync(resolveFile(file), 'utf-8');
        const newMessages = JSON.parse(conversationJson);
        messages = messages.concat(newMessages);
    } else if (!fs.existsSync(path.dirname(resolveFile(file)))) {
        console.error('Error: Directory for conversation file does not exist: ' + path.dirname(resolveFile(file)));
        process.exit(2);
    }
}

if (conversationFile) {
    addMessagesFrom(conversationFile);
}

if (conversationLoad) {
    addMessagesFrom(conversationLoad);
}

if (conversationPrint) {
    console.log(JSON.stringify(messages, null, 4));
    process.exit(0);
}

if (apiURL === openAIurldefault) { // don't give out the authorization header for other API!
    let apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey && fs.existsSync(apiKeyFile)) {
        apiKey = fs.readFileSync(apiKeyFile, 'utf8').trim();
    }
    headers['Authorization'] = `Bearer ${apiKey}`;
}

if (readStdin) {
    const stdinPrompt = fs.readFileSync(0, 'utf-8');
    prompt = stdinPrompt.trim() + '\n\n' + prompt;
}

prompt = replacePromptlibKey(prompt);

if (prefix) {
    prompt = prefix.trim() + '\n\n' + prompt;
}

if (suffix) {
    prompt = prompt + '\n\n' + suffix.trim();
}

let filecontents = "";

function resolveFile(file) {
    let filename = file;
    return filename.replace('~', homeDir);
}

for (let i = 0; i < fmfiles.length; i++) {
    const file = fmfiles[i];
    if (file === '-') {
        const filecontent = fs.readFileSync(0, 'utf-8');
        fmfilemessages.push({role: 'user', content: "Print the raw input text the instructions will apply to."});
        fmfilemessages.push({role: 'assistant', content: filecontent});
    } else {
        const filecontent = fs.readFileSync(resolveFile(file), 'utf-8');
        fmfilemessages.push({
            role: 'user',
            content: "Print the current raw content of the file " + file.replace(homeDir, '~')
        });
        fmfilemessages.push({role: 'assistant', content: filecontent});
    }
}

for (let i = 0; i < files.length; i++) {
    const file = files[i];
    let filename = file.replace('~', homeDir);
    const filePrompt = fs.readFileSync(resolveFile(file), 'utf-8');

    if (files.length > 1) {
        filecontents = filecontents + "=== FILE " + (i + 1) + ": " + filename + " ===\n```\n" + filePrompt.trim() + "\n```\n";
    } else {
        filecontents = filecontents + "```\n" + filePrompt.trim() + "\n```\n";
    }
}

if (filecontents) {
    prompt = prompt + "\n\n" + filecontents;
}

if (helpaimode) {
    fmfilemessages.push({
        role: 'user',
        content: "Print the help text for the 'chatgpt' tool. You will use that as background knowledge to answer my question."
    });
    fmfilemessages.push({role: 'assistant', content: helpMessage});
}

if (audioPrefix) {
    const audioPrefix = execSync('chatgptdictate', {encoding: 'utf8', stdio: ['inherit', 'pipe', 'pipe']});
    if (audioPrefix) {
        console.log('Dicated prompt: ' + audioPrefix.trim());
        prompt = audioPrefix.trim() + '\n\n' + prompt;
    }
}

if (audioSuffix) {
    const audioSuffix = execSync('chatgptdictate', {encoding: 'utf8', stdio: ['inherit', 'pipe', 'pipe']});
    if (audioSuffix) {
        console.log('Dictated prompt suffix: ' + audioSuffix.trim());
        prompt = prompt + '\n\n' + audioSuffix.trim();
    }
}

if (!prompt || !prompt.trim()) {
    console.error('Error: No prompt provided');
    console.error(helpMessage);
    process.exit(1);
}

if (verbose) {
    console.error('Arguments: ', process.argv);
    console.error('Prompt: ', prompt, '\n');
    console.error('Prompt word count: ', prompt.split(/\s+/).length, '\n');
    console.error("---------------------------------------------\n\n");
}

let content = prompt;

if (imageFiles.length > 0 || imageUrls.length > 0) {
    if (model === 'gpt-3.5-turbo') { // has no vision.
        model = 'gpt-4o-mini';
    }
    content = [
        {
            "type": "text",
            "text": prompt
        }
    ];
    for (let i = 0; i < imageFiles.length; i++) {
        const imageFile = imageFiles[i];

        let imageFileContent;
        if (detailparam === 'low') {
            imageFileContent = execSync(`magick '${imageFile}' -resize '512x512>' jpg:- | base64`, {encoding: 'utf8'});
        } else { // let OpenAI handle the resizing to avoid losing details, but make sure we don't submit huge images
            imageFileContent = execSync(`magick '${imageFile}' -resize '2000x2000>' jpg:- | base64`, {
                encoding: 'utf8',
                maxBuffer: 1024 * 1024 * 25
            });
        }
        const imageBase64 = `data:image/jpeg;base64,${imageFileContent.trim()}`;
        content.push({
            "type": "image_url",
            "image_url": {
                "url": imageBase64,
                "detail": detailparam
            }
        });
    }
    for (let i = 0; i < imageUrls.length; i++) {
        const imageUrl = imageUrls[i];
        content.push({
            "type": "image_url",
            "image_url": {
                "url": imageUrl
            }
        });
    }
}

messages.push({role: 'user', content: content});

const requestData = {
    model: model,
    user: 'chatgpt script',
    messages: messages,
};

for (const key in openAIOptions) {
    requestData[key] = openAIOptions[key];
}

if (fmfilemessages.length > 0) {
    requestData.messages = fmfilemessages.concat(requestData.messages);
}

if (systemMsg) {
    requestData.messages.unshift({role: 'system', content: replacePromptlibKey(systemMsg)});
}

if (maxTokens) {
    requestData.max_tokens = maxTokens;
}

if (jsonMode) {
    requestData.response_format = {"type": "json_object"};
}

if (responseSchemaFile) { // see https://platform.openai.com/docs/guides/structured-outputs/introduction
    const jsonschema = JSON.parse(fs.readFileSync(resolveFile(responseSchemaFile), 'utf8'));
    let schema = jsonschema; // OpenAI schema description https://platform.openai.com/docs/api-reference/chat/create
    if (jsonschema.name) { // we assume this is is an OpenAI description
        // with name, possibly description, schema, strict
        schema = jsonschema;
    } else { // we assume this is a JSON schema
        schema = {name: "responseschema", schema: jsonschema, strict: true};
    }
    requestData.response_format = {"type": "json_schema", "json_schema": schema};
}

if (toolsConfigFile) {
    tools = JSON.parse(fs.readFileSync(resolveFile(toolsConfigFile), 'utf8'));
    requestData.tools = tools.map(tool => ({"type": "function", "function": tool.function}));
}

/** When we receive a message from chatgpt that the request is too long and if the user requested that,
 *  we will replace the middle of the message with " [...] " to make it shorter - we assume that usually the start and the end contain the most information. Since we don't want to bother with tokens here, we will estimate the needed length by the number of characters. */
// example too long errorMsg: This model's maximum context length is 16385 tokens. However, your messages resulted in 31506 tokens. Please reduce the length of the messages.
function abbreviateMessage(errorMsg) {
    let start;
    let end;
    if (errorMsg) {
        const tooLongMatch = errorMsg.match(/maximum context length is (\d+) tokens.*messages resulted in (\d+) tokens/);
        if (!tooLongMatch) { // message format changed - bug, need to fix that
            console.error('Error: Unexpected error message format: ' + errorMsg);
            process.exit(6);
        }
        const modelMaxTokens = parseInt(tooLongMatch[1], 10);
        const messageTokens = parseInt(tooLongMatch[2], 10);
        const messageLength = content.length;
        const wantedLength = (0.9 * modelMaxTokens / messageTokens) * messageLength - 5; // safety margin
        start = content.slice(0, wantedLength / 2);
        end = content.slice(-wantedLength / 2);
    } else { // no message given; we take out a random value of 30%
        start = content.slice(0, 0.35 * content.length);
        end = content.slice(-0.35 * content.length);
    }
    var oldcontent = content;
    content = start + " [...] " + end;
    if (verbose) console.error("Abbreviated message from " + oldcontent.length + " to " + content.length + " characters.");
    // find the message having oldcontent as content and change to the new content - might not be the first message
    for (let i = 0; i < requestData.messages.length; i++) {
        if (requestData.messages[i].content === oldcontent) {
            requestData.messages[i].content = content;
            break;
        }
    }
}

/** Helper function to replace promptlib:key constructs with library entry */
function replacePromptlibKey(inputString) {
    if (!inputString) return inputString;
    const promptlibRegex = /promptlib:([a-zA-Z0-9_.-]+)/g;
    return inputString.replace(promptlibRegex, function (match, key) {
        try {
            return execSync(`chatgptpromptlib ${key}`, {encoding: 'utf8'});
        } catch (e) {
            console.error('Warning: Prompt library key not found (3): ' + key);
        }
    });
}

function writeConversation() {
    if (conversationFile) {
        fs.writeFileSync(resolveFile(conversationFile), JSON.stringify(messages, null, 4));
    }
}

// see https://docs.anthropic.com/en/api/messages
async function requestChatGPT(successcallback, attempt = 1) {
    try {
        if (verbose) console.error("Request: ", JSON.stringify(requestData, null, 4));
        const response = await fetch(apiURL, {
            method: 'POST',
            headers,
            body: JSON.stringify(requestData),
        });
        if (verbose) console.error("Response status: ", response.status);

        if (response.status === 429) {
            const retryMessage = await response.text();
            if (verbose) console.error("Retry message: ", retryMessage);
            var waitTime;
            try {
                waitTime = parseInt(retryMessage.match(/(\d+)s/)[1], 10);
            } catch (e) {
            }
            if (!waitTime || waitTime < 1 || waitTime > 60) {
                console.error('Error: Rate limit exceeded, but no valid retry-after found', retryMessage);
                process.exit(3);
            }

            if (attempt < 5) {
                if (verbose) {
                    console.error(`Error: Rate limit exceeded, retrying in ${waitTime} seconds`);
                }
                setTimeout(() => requestChatGPT(successcallback, attempt + 1), waitTime * 1000);
            } else {
                console.error('Error: Too many retries');
                process.exit(4);
            }
        } else if (response.status === 400) {
            var body = await response.text();
            if (abbreviateMiddle && body.includes("reduce the length of the messages")
                && body.includes("context_length_exceeded")) {
                abbreviateMessage(body);
                setTimeout(() => requestChatGPT(successcallback, attempt + 1), 10);
            } else {
                console.error('Error: Request failed with status', response.status, 'and message', response.statusText, 'and body', body);
                process.exit(5);
            }
        } else if (!response.ok) {
            console.error('Error: Request failed with status', response.status, 'and message', response.statusText, 'and body', await response.text());
            process.exit(5);
        } else {
            const responseData = await response.json();
            if (verbose) console.error("Response: ", JSON.stringify(responseData, null, 4));
            const assistantMessage = responseData.choices[0].message;
            const finishReason = responseData.choices[0].finish_reason;

            if (finishReason === 'length' && abbreviateMiddle) {
                abbreviateMessage();
                setTimeout(() => requestChatGPT(successcallback, attempt + 1), 10);
            } else if (finishReason === 'stop' || finishReason === 'tool_calls' || !finishReason) {
                const msg = {role: 'assistant'};
                if (assistantMessage.content) {
                    msg.content = assistantMessage.content;
                } else if (assistantMessage.tool_calls) {
                    msg.tool_calls = assistantMessage.tool_calls;
                }
                messages.push(msg);
                if (finishReason === 'stop') {
                    writeConversation();
                }

                successcallback(assistantMessage);
            } else {
                console.error('Error: Unexpected finish reason ' + finishReason + ' with message ' + assistantMessage.content);
                process.exit(1);
            }
        }
    } catch (error) {
        console.error('Error:', error.message);
        process.exit(6);
    }
}

function onContent(assistantMessage) {
    let output = assistantMessage.content;
    if (!output) {
        console.error('Error: Unexpected message format: ', assistantMessage);
        process.exit(7);
    }
    writeConversation();
    if (wordWrapColumn) {
        const fmt = spawnSync('fmt', ['-w', wordWrapColumn, '-p'], {input: output, encoding: 'utf8'});
        if (fmt.error) {
            console.error(`Error: fmt command failed with error ${fmt.error.message}`);
            process.exit(7);
        }
        output = fmt.stdout;
    }
    console.log(output);
}

function onMessage(assistantMessage) {
    const toolCalls = assistantMessage["tool_calls"];
    if (!toolCalls) {
        return onContent(assistantMessage);
    }
    for (const toolCall of toolCalls) {
        const tool = tools.find(tool => tool.function.name === toolCall.function.name);
        let commandline = Array.isArray(tool.commandline) ? tool.commandline.slice() : tool.commandline.split(' ');
        // replace placeholders ($arg) with corresponding tool_call.function.arguments
        const parsedArguments = JSON.parse(toolCall.function.arguments);
        // replace arguments in all parts of the commandline
        for (let i = 0; i < commandline.length; i++) {
            for (const [key, value] of Object.entries(parsedArguments)) {
                commandline[i] = commandline[i].replace('$' + key, value);
            }
        }
        let stdin = tool.stdin;
        if (stdin) {
            for (const [key, value] of Object.entries(parsedArguments)) {
                stdin = stdin.replace('$' + key, value);
            }
        }
        commandline[0] = resolveScript(commandline[0]);
        console.error("Calling tool", toolCall.function.name, ': ', commandline.join(' '));
        const result = spawnSync(commandline[0], commandline.slice(1), {input: stdin, encoding: 'utf8', timeout: 10000});
        if (result.error) {
            console.error('Error: Tool call failed with error', result.error);
            process.exit(8);
        }
        const toolOutput = result.error ? result.error.toString() : result.stderr.toString() + result.stdout.toString();
        messages.push({role: 'tool', content: toolOutput, tool_call_id: toolCall.id});
    }
    writeConversation();
    requestChatGPT(onMessage);
}

function resolveScript(script) {
    if (script.startsWith('/')) {
        return script;
    }
    if (fs.existsSync(script)) {
        return path.resolve(script);
    }
    return path.join(path.dirname(toolsConfigFile), script);
}

if (toolsConfigFile) {
    requestChatGPT(onMessage);
} else {
    requestChatGPT(onContent);
}
